{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "998d39ec",
   "metadata": {},
   "source": [
    "# Gather Customer Data from SQL Server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06abde7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymssql\n",
    "import re\n",
    "import pandas as pd\n",
    "import pandas_dedupe\n",
    "from ftfy import fix_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d994bb0",
   "metadata": {},
   "source": [
    "#### Cleanup ugly strings that cause headaches for CSV reading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbd61056",
   "metadata": {},
   "outputs": [],
   "source": [
    "dupsrx = re.compile(r'(.)\\1{5,}') # Search for any thing that has more than 5 repeated characters\n",
    "chars_to_remove = [\")\",\"(\",\"|\",\"[\",\"]\",\"{\",\"}\",\"'\",\"\\\"\", \",\"]\n",
    "badcharsrx = re.compile('[' + re.escape(''.join(chars_to_remove)) + ']') # Replace quotes and commas.\n",
    "badaddress = re.compile(r'bad address',flags=re.IGNORECASE)\n",
    "unabletoforward = re.compile(r'unable to', flags=re.IGNORECASE)\n",
    "\n",
    "\n",
    "def fixstring(string):\n",
    "    string = str(string)\n",
    "    string = fix_text(string) # fix text\n",
    "    string = string.encode(\"ascii\", errors=\"ignore\").decode() #remove non ascii chars\n",
    "    string = string.lower()\n",
    "    string = badcharsrx.sub('', string)\n",
    "    string = string.replace('&', 'and')\n",
    "    string = string.lower() # normalise case\n",
    "    string = re.sub(' +',' ',string).strip() # get rid of multiple spaces and replace with a single\n",
    "    if string == '' or string.isspace() or dupsrx.search(string) != None or badaddress.search(string) != None or unabletoforward.search(string) != None :\n",
    "        string = 'nan'\n",
    "\n",
    "    return string\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee8bb5bb",
   "metadata": {},
   "source": [
    "#### Iterate through each database and download raw customer data.  Cleanup before outputting to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd08dba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "server = r'server' \n",
    "database = '' \n",
    "username = 'user' \n",
    "password = 'password' \n",
    "stores = [ '511', '512', '582', '310', '316', '321', '501', '504', '519', '550', '566' ]\n",
    "custfile = open('customers.csv', 'w', encoding='utf-8')\n",
    "\n",
    "custfile.write('ID,StoreID,Company,FirstName,LastName,Address,Address2,City,State,Zip,EmailAddress,PhoneNumber\\n')\n",
    "for stid in stores:\n",
    "    print('Working on Store: ' + stid, end='')\n",
    "    database = 's' + stid\n",
    "    cnxn = pymssql.connect(server, username, password, database)\n",
    "    cursor = cnxn.cursor()\n",
    "    query = r\"\"\"select Customer.ID,'{storeid}' as StoreID,Company,FirstName,LastName,[Address],Address2,City,[State],Zip,EmailAddress,PhoneNumber\n",
    "    from Customer\n",
    "    where Customer.AccountNumber <> 'CASH' and \n",
    "        TotalVisits >= 3 and\n",
    "        Customer.ID in (select distinct CustomerID from [Transaction])\"\"\".format(storeid=stid)\n",
    "    cursor.execute(query)\n",
    "    for row in cursor:\n",
    "        ndx = 0\n",
    "        strikes = 0\n",
    "        outrow = ''\n",
    "        for col in row:\n",
    "            if ndx > 1:\n",
    "                clean = fixstring(col)\n",
    "            else:\n",
    "                clean = str(col)\n",
    "            if clean == 'nan':\n",
    "                strikes = strikes+1\n",
    "            outrow = outrow + clean\n",
    "            ndx = ndx + 1 \n",
    "            if ndx < len(row):\n",
    "                outrow = outrow + ','               \n",
    "                \n",
    "        if strikes <= 4:\n",
    "            custfile.write(outrow)\n",
    "            custfile.write('\\n')\n",
    "    print(' Done.')\n",
    "\n",
    "custfile.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10273f87",
   "metadata": {},
   "source": [
    "#### Attempt Training on subset of actual file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "362ad7a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('customers.csv', encoding='utf-8', nrows=20000)\n",
    "df = pandas_dedupe.dedupe_dataframe(df, ['Company', 'FirstName', 'LastName', 'Address', 'City', 'State', 'Zip', 'PhoneNumber'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "735ccece",
   "metadata": {},
   "source": [
    "#### Re-Read entire file and dedupe based on training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9876b977",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing data ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\anand.HOME\\AppData\\Local\\Temp\\ipykernel_9596\\61623702.py:2: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df = pandas_dedupe.dedupe_dataframe(df, ['Company', 'FirstName', 'LastName', 'Address', 'City', 'State', 'Zip', 'PhoneNumber'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading from dedupe_dataframe_learned_settings\n",
      "Clustering...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A component contained 66138 elements. Components larger than 30000 are re-filtered. The threshold for this filtering is 2.735057171410285e-24\n",
      "A component contained 66137 elements. Components larger than 30000 are re-filtered. The threshold for this filtering is 7.55496214688561e-24\n",
      "A component contained 66114 elements. Components larger than 30000 are re-filtered. The threshold for this filtering is 2.0549916930140488e-23\n",
      "A component contained 66088 elements. Components larger than 30000 are re-filtered. The threshold for this filtering is 5.587602355957443e-23\n",
      "A component contained 65934 elements. Components larger than 30000 are re-filtered. The threshold for this filtering is 1.5189199419679814e-22\n",
      "A component contained 65460 elements. Components larger than 30000 are re-filtered. The threshold for this filtering is 4.1288524771356315e-22\n",
      "A component contained 64761 elements. Components larger than 30000 are re-filtered. The threshold for this filtering is 1.122342747488234e-21\n",
      "A component contained 63710 elements. Components larger than 30000 are re-filtered. The threshold for this filtering is 3.0508438958000657e-21\n",
      "A component contained 61979 elements. Components larger than 30000 are re-filtered. The threshold for this filtering is 8.293085158967458e-21\n",
      "A component contained 59793 elements. Components larger than 30000 are re-filtered. The threshold for this filtering is 2.2543028684150495e-20\n",
      "A component contained 57200 elements. Components larger than 30000 are re-filtered. The threshold for this filtering is 6.127830523055731e-20\n",
      "A component contained 54439 elements. Components larger than 30000 are re-filtered. The threshold for this filtering is 1.665717035869908e-19\n",
      "A component contained 51495 elements. Components larger than 30000 are re-filtered. The threshold for this filtering is 4.527888349959834e-19\n",
      "A component contained 48634 elements. Components larger than 30000 are re-filtered. The threshold for this filtering is 1.2308546147805034e-18\n",
      "A component contained 45963 elements. Components larger than 30000 are re-filtered. The threshold for this filtering is 3.345950131542093e-18\n",
      "A component contained 44719 elements. Components larger than 30000 are re-filtered. The threshold for this filtering is 9.09582528531253e-18\n",
      "A component contained 44173 elements. Components larger than 30000 are re-filtered. The threshold for this filtering is 2.4732091483914872e-17\n",
      "A component contained 43659 elements. Components larger than 30000 are re-filtered. The threshold for this filtering is 6.727907932651687e-17\n",
      "A component contained 43403 elements. Components larger than 30000 are re-filtered. The threshold for this filtering is 1.8295816203998671e-16\n",
      "A component contained 43327 elements. Components larger than 30000 are re-filtered. The threshold for this filtering is 4.979792033137594e-16\n",
      "A component contained 43302 elements. Components larger than 30000 are re-filtered. The threshold for this filtering is 1.3678237524730804e-15\n",
      "A component contained 43174 elements. Components larger than 30000 are re-filtered. The threshold for this filtering is 3.720684365170331e-15\n",
      "A component contained 43133 elements. Components larger than 30000 are re-filtered. The threshold for this filtering is 1.0121780968810313e-14\n",
      "A component contained 42955 elements. Components larger than 30000 are re-filtered. The threshold for this filtering is 2.751437806926831e-14\n",
      "A component contained 42505 elements. Components larger than 30000 are re-filtered. The threshold for this filtering is 7.479197658128041e-14\n",
      "A component contained 41599 elements. Components larger than 30000 are re-filtered. The threshold for this filtering is 2.033064464064782e-13\n",
      "A component contained 40484 elements. Components larger than 30000 are re-filtered. The threshold for this filtering is 5.526452729613906e-13\n",
      "A component contained 38940 elements. Components larger than 30000 are re-filtered. The threshold for this filtering is 1.5023315647161128e-12\n",
      "A component contained 36621 elements. Components larger than 30000 are re-filtered. The threshold for this filtering is 4.083776171021665e-12\n",
      "A component contained 34145 elements. Components larger than 30000 are re-filtered. The threshold for this filtering is 1.1102209724628994e-11\n",
      "A component contained 31957 elements. Components larger than 30000 are re-filtered. The threshold for this filtering is 3.018296454135663e-11\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# duplicate sets 129880\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('customers.csv', encoding='utf-8', nrows=140000)\n",
    "df = pandas_dedupe.dedupe_dataframe(df, ['Company', 'FirstName', 'LastName', 'Address', 'City', 'State', 'Zip', 'PhoneNumber'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a61eb3f",
   "metadata": {},
   "source": [
    "### Get Transactions for customers:  \n",
    "Cluster Customers to a sigle ID; Label based on price category, department and brand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e568138",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('scrubbed.csv')\n",
    "grouped = df.groupby(\"StoreID\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8c37cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymssql\n",
    "tranfile = open('transactions.csv', 'w', encoding='utf-8')\n",
    "tranfile.write('CustomerID,ItemLookupCode,TranTime,PriceCategory,Department,Brand\\n')\n",
    "\n",
    "def priceCategory(price):\n",
    "    if price < 10:\n",
    "        return '1'\n",
    "    if price >=10 and price < 100:\n",
    "        return '2'\n",
    "    if price >=100 and price < 500:\n",
    "        return '3'\n",
    "    if price >=500 and price < 1000:\n",
    "        return '4'\n",
    "    if price >=1000:\n",
    "        return '5'\n",
    "    return '0'\n",
    "\n",
    "for name, group in grouped:\n",
    "    print('Working on Store: ' + name)\n",
    "    database = 's' + name\n",
    "    cnxn = pymssql.connect(server, username, password, database)\n",
    "    cursor = cnxn.cursor()\n",
    "    for index, entry in df.iterrows():\n",
    "        query = r\"\"\"select Customer.ID,ItemLookupCode, [Transaction].\"Time\", TransactionEntry.Price, TransactionEntry.Quantity, Department.Name, BinLocationXRef.RetailCD\n",
    "from Customer, [Transaction], TransactionEntry, Item, Department, BinLocationXRef\n",
    "where Customer.ID=[Transaction].CustomerID and \n",
    "      [Transaction].TransactionNumber=TransactionEntry.TransactionNumber and\n",
    "      Item.ID=TransactionEntry.ItemID and \n",
    "      Department.ID=Item.DepartmentID and\n",
    "      item.BinLocation=BinLocationXRef.RetailBinCD and\n",
    "      Customer.ID={custid} and Department.Code not in ('WP01', '990', '970', 'GC','TAX', 'SHIP' )\"\"\".format(custid=entry['ID'])\n",
    "        cursor.execute(query)\n",
    "        for row in cursor:\n",
    "            tranfile.write(entry[0] + ',' + str(row[1]) + ',' + str(row[2]) + ',' + priceCategory(row[3]) + ',' + str(row[5]) + ',' + str(row[6]) +'\\n')\n",
    "    print('Done!')\n",
    "tranfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28c59522",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3 (tf)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
