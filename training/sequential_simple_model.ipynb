{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pprint\n",
    "import tempfile\n",
    "\n",
    "from typing import Dict, Text\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import tensorflow_recommenders as tfrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_filename = \"../data/samples/train_transactions_gt2018.tfrecord\"\n",
    "train = tf.data.TFRecordDataset(train_filename)\n",
    "\n",
    "test_filename = \"../data/samples/test_transactions_gt2018.tfrecord\"\n",
    "test = tf.data.TFRecordDataset(test_filename)\n",
    "\n",
    "feature_description = {\n",
    "    'context_item_id': tf.io.FixedLenFeature([10], tf.int64, default_value=np.repeat(0, 10)),\n",
    "    'context_item_quantity': tf.io.FixedLenFeature([10], tf.float32, default_value=np.repeat(0, 10)),\n",
    "    'context_item_price': tf.io.FixedLenFeature([10], tf.float32, default_value=np.repeat(0, 10)),\n",
    "    'context_item_department_id': tf.io.FixedLenFeature([10], tf.int64, default_value=np.repeat(0, 10)),\n",
    "    'context_discount_id': tf.io.FixedLenFeature([10], tf.int64, default_value=np.repeat(0, 10)),\n",
    "    'context_return_id': tf.io.FixedLenFeature([10], tf.int64, default_value=np.repeat(0, 10)),   \n",
    "    'label_item_id': tf.io.FixedLenFeature([1], tf.int64, default_value=0),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _parse_function(example_proto):\n",
    "  return tf.io.parse_single_example(example_proto, feature_description)\n",
    "\n",
    "train_ds = train.map(_parse_function).map(lambda x: {\n",
    "    \"context_item_id\": tf.strings.as_string(x[\"context_item_id\"]),\n",
    "    \"label_item_id\": tf.strings.as_string(x[\"label_item_id\"])\n",
    "})\n",
    "\n",
    "test_ds = test.map(_parse_function).map(lambda x: {\n",
    "    \"context_item_id\": tf.strings.as_string(x[\"context_item_id\"]),\n",
    "    \"label_item_id\": tf.strings.as_string(x[\"label_item_id\"])\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'context_item_id': array([b'95626', b'33553', b'33553', b'98609', b'150187', b'85219',\n",
      "       b'85205', b'33553', b'91241', b'75745'], dtype=object),\n",
      " 'label_item_id': array([b'75825'], dtype=object)}\n"
     ]
    }
   ],
   "source": [
    "for x in train_ds.take(1).as_numpy_iterator():\n",
    "  pprint.pprint(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "items_filename = \"../data/samples/items.tfrecord\"\n",
    "items_tf = tf.data.TFRecordDataset(items_filename)\n",
    "item_feature_description = {\n",
    "    'item_id': tf.io.FixedLenFeature([1], tf.int64, default_value=0),\n",
    "    'item_description': tf.io.FixedLenFeature([1], tf.string, default_value='None')}\n",
    "def item_parse_function(example_proto):\n",
    "  return tf.io.parse_single_example(example_proto, item_feature_description)\n",
    "\n",
    "items_ds = items_tf.map(item_parse_function).map(lambda x: {\n",
    "    \"item_id\": tf.strings.as_string(x[\"item_id\"]),\n",
    "    \"item_description\": x[\"item_description\"],\n",
    "})\n",
    "items = items_ds.map(lambda x: x[\"item_id\"])\n",
    "item_ids = items.batch(1_000)\n",
    "unique_item_ids = np.unique(np.concatenate(list(item_ids)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dimension = 32\n",
    "\n",
    "query_model = tf.keras.Sequential([\n",
    "    tf.keras.layers.StringLookup(\n",
    "      vocabulary=unique_item_ids, mask_token=None),\n",
    "    tf.keras.layers.Embedding(len(unique_item_ids) + 1, embedding_dimension), \n",
    "    tf.keras.layers.GRU(embedding_dimension),\n",
    "])\n",
    "\n",
    "candidate_model = tf.keras.Sequential([\n",
    "  tf.keras.layers.StringLookup(\n",
    "      vocabulary=unique_item_ids, mask_token=None),\n",
    "  tf.keras.layers.Embedding(len(unique_item_ids) + 1, embedding_dimension)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = tfrs.metrics.FactorizedTopK(\n",
    "  candidates=items_tf.batch(128).map(candidate_model)\n",
    ")\n",
    "\n",
    "task = tfrs.tasks.Retrieval(\n",
    "  metrics=metrics\n",
    ")\n",
    "\n",
    "class MyModel(tfrs.Model):\n",
    "\n",
    "    def __init__(self, query_model, candidate_model):\n",
    "        super().__init__()\n",
    "        self._query_model = query_model\n",
    "        self._candidate_model = candidate_model\n",
    "\n",
    "        self._task = task\n",
    "\n",
    "    def compute_loss(self, features, training=False):\n",
    "        purchase_history = features[\"context_item_id\"]\n",
    "        next_item = features[\"label_item_id\"]\n",
    "\n",
    "        query_embedding = self._query_model(purchase_history)       \n",
    "        candidate_embedding = self._candidate_model(next_item)\n",
    "\n",
    "        return self._task(query_embedding, candidate_embedding, compute_metrics=not training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MyModel(query_model, candidate_model)\n",
    "model.compile(optimizer=tf.keras.optimizers.Adagrad(learning_rate=0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "cached_train = train_ds.shuffle(10_000).batch(12800).cache()\n",
    "cached_test = test_ds.batch(2560).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "89/89 [==============================] - 63s 468ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 107068.8000 - regularization_loss: 0.0000e+00 - total_loss: 107068.8000\n",
      "Epoch 2/5\n",
      "89/89 [==============================] - 9s 104ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 98200.7333 - regularization_loss: 0.0000e+00 - total_loss: 98200.7333\n",
      "Epoch 3/5\n",
      "89/89 [==============================] - 9s 103ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 95494.3728 - regularization_loss: 0.0000e+00 - total_loss: 95494.3728\n",
      "Epoch 4/5\n",
      "89/89 [==============================] - 9s 104ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 93964.4141 - regularization_loss: 0.0000e+00 - total_loss: 93964.4141\n",
      "Epoch 5/5\n",
      "89/89 [==============================] - 9s 104ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 92911.0965 - regularization_loss: 0.0000e+00 - total_loss: 92911.0965\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1c11e58dee0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(cached_train, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "110/110 [==============================] - 253s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.9034 - factorized_top_k/top_5_categorical_accuracy: 0.9034 - factorized_top_k/top_10_categorical_accuracy: 0.9034 - factorized_top_k/top_50_categorical_accuracy: 0.9034 - factorized_top_k/top_100_categorical_accuracy: 0.9034 - loss: 15468.9167 - regularization_loss: 0.0000e+00 - total_loss: 15468.9167\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'factorized_top_k/top_1_categorical_accuracy': 0.9034018516540527,\n",
       " 'factorized_top_k/top_5_categorical_accuracy': 0.9034018516540527,\n",
       " 'factorized_top_k/top_10_categorical_accuracy': 0.9034018516540527,\n",
       " 'factorized_top_k/top_50_categorical_accuracy': 0.9034018516540527,\n",
       " 'factorized_top_k/top_100_categorical_accuracy': 0.9034018516540527,\n",
       " 'loss': 13.817108154296875,\n",
       " 'regularization_loss': 0,\n",
       " 'total_loss': 13.817108154296875}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(cached_test, return_dict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor. Received: inputs={'context_item_id': <tf.Tensor: shape=(1, 10, 1), dtype=string, numpy=\n",
      "array([[[b'79561120959008675364483521446308526175279128909128910'],\n",
      "        [b'79561120959008675364483521446308526175279128909128910'],\n",
      "        [b'79561120959008675364483521446308526175279128909128910'],\n",
      "        [b'79561120959008675364483521446308526175279128909128910'],\n",
      "        [b'79561120959008675364483521446308526175279128909128910'],\n",
      "        [b'79561120959008675364483521446308526175279128909128910'],\n",
      "        [b'79561120959008675364483521446308526175279128909128910'],\n",
      "        [b'79561120959008675364483521446308526175279128909128910'],\n",
      "        [b'79561120959008675364483521446308526175279128909128910'],\n",
      "        [b'79561120959008675364483521446308526175279128909128910']]],\n",
      "      dtype=object)>}. Consider rewriting this model with the Functional API.\n",
      "tf.Tensor(\n",
      "[[[b'92242']\n",
      "  [b'12099']\n",
      "  [b'92246']\n",
      "  [b'70957']\n",
      "  [b'92248']\n",
      "  [b'138276']\n",
      "  [b'92240']\n",
      "  [b'70956']\n",
      "  [b'70958']\n",
      "  [b'89285']\n",
      "  [b'130619']\n",
      "  [b'92244']]], shape=(1, 12, 1), dtype=string)\n"
     ]
    }
   ],
   "source": [
    "# Create a model that takes in raw query features, and\n",
    "index = tfrs.layers.factorized_top_k.BruteForce(model._query_model, k=12)\n",
    "# recommends movies out of the entire movies dataset.\n",
    "index.index_from_dataset(\n",
    "  tf.data.Dataset.zip((items.batch(100), items.batch(100).map(model._candidate_model)))\n",
    ")\n",
    "\n",
    "feature0 = [\"7956\" \"112095\" \"90086\" \"75364\" \"48352\" \"144630\" \"85261\" \"75279\" \"128909\" \"128910\"]\n",
    "features_dataset = { \n",
    "  'context_item_id' : tf.constant(feature0,shape=(1,10,1)), \n",
    "}\n",
    "\n",
    "_, predicted = index(features_dataset)\n",
    "print(predicted)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor. Received: inputs={'context_item_id': <tf.Tensor 'context_item_id:0' shape=(None, 10, 1) dtype=string>}. Consider rewriting this model with the Functional API.\n",
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor. Received: inputs={'context_item_id': <tf.Tensor 'inputs:0' shape=(None, 10, 1) dtype=string>}. Consider rewriting this model with the Functional API.\n",
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor. Received: inputs={'context_item_id': <tf.Tensor 'inputs:0' shape=(None, 10, 1) dtype=string>}. Consider rewriting this model with the Functional API.\n",
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor. Received: inputs={'context_item_id': <tf.Tensor 'queries/context_item_id:0' shape=(None, 10, 1) dtype=string>}. Consider rewriting this model with the Functional API.\n",
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor. Received: inputs={'context_item_id': <tf.Tensor 'queries/context_item_id:0' shape=(None, 10, 1) dtype=string>}. Consider rewriting this model with the Functional API.\n",
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor. Received: inputs={'context_item_id': <tf.Tensor 'inputs/context_item_id:0' shape=(None, 10, 1) dtype=string>}. Consider rewriting this model with the Functional API.\n",
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor. Received: inputs={'context_item_id': <tf.Tensor 'inputs/context_item_id:0' shape=(None, 10, 1) dtype=string>}. Consider rewriting this model with the Functional API.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as query_with_exclusions, gru_cell_layer_call_fn, gru_cell_layer_call_and_return_conditional_losses while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../data/simple_seq_model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../data/simple_seq_model\\assets\n"
     ]
    }
   ],
   "source": [
    "path = '../data/simple_seq_model'\n",
    "tf.saved_model.save(index, path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('tf')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "d7f156ea84fdc221bcc828ba074462c25de1a00a239b7857dab945319d42b0e1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
