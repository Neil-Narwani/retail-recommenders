{"cells":[{"cell_type":"code","execution_count":16,"metadata":{"id":"bPMLsdrfZKd8"},"outputs":[],"source":["import os\n","import pprint\n","import tempfile\n","\n","from typing import Dict, Text\n","\n","import numpy as np\n","import tensorflow as tf\n","import tensorflow_datasets as tfds\n","import tensorflow_recommenders as tfrs"]},{"cell_type":"code","execution_count":17,"metadata":{"id":"_H3wIkMsZKeC"},"outputs":[],"source":["train_filename = \"../data/samples/train_transactions_rich.tfrecord\"\n","train = tf.data.TFRecordDataset(train_filename)\n","\n","test_filename = \"../data/samples/test_transactions_rich.tfrecord\"\n","test = tf.data.TFRecordDataset(test_filename)\n","\n","feature_description = {\n","    'context_item_id': tf.io.FixedLenFeature([10], tf.int64, default_value=np.repeat(0, 10)),    \n","    'context_item_price': tf.io.FixedLenFeature([10], tf.float32, default_value=np.repeat(0, 10)),\n","    'context_item_discount': tf.io.FixedLenFeature([10], tf.float32, default_value=np.repeat(0, 10)),\n","    'context_item_description': tf.io.FixedLenFeature([10], tf.string, default_value=np.repeat('None', 10)), \n","    'label_item_id': tf.io.FixedLenFeature([1], tf.int64, default_value=0),\n","}\n","\n","def _parse_function(example_proto):\n","  return tf.io.parse_single_example(example_proto, feature_description)\n","def _map_function(x):\n","  return {\n","    \"context_item_id\": tf.strings.as_string(x[\"context_item_id\"]),\n","    \"context_item_description\": x[\"context_item_description\"],\n","    \"context_item_price\": x[\"context_item_price\"],\n","    \"context_item_discount\": x[\"context_item_discount\"],\n","    \"label_item_id\": tf.strings.as_string(x[\"label_item_id\"])}\n","    \n","train_ds = train.map(_parse_function).map(_map_function)\n","test_ds = test.map(_parse_function).map(_map_function)"]},{"cell_type":"code","execution_count":18,"metadata":{"id":"teg9ThGDZKeJ"},"outputs":[],"source":["items_filename = \"../data/samples/items.tfrecord\"\n","items_tf = tf.data.TFRecordDataset(items_filename)\n","item_feature_description = {\n","    'item_id': tf.io.FixedLenFeature([1], tf.int64, default_value=0),\n","    'item_fullprice' : tf.io.FixedLenFeature([1], tf.float32, default_value=0),\n","    'item_description': tf.io.FixedLenFeature([1], tf.string, default_value='None')}\n","def item_parse_function(example_proto):\n","  return tf.io.parse_single_example(example_proto, item_feature_description)\n","\n","items_ds = items_tf.map(item_parse_function).map(lambda x: {\n","    \"item_id\": tf.strings.as_string(x[\"item_id\"]),\n","    \"item_description\": x[\"item_description\"],\n","})\n","\n","item_ids = items_ds.map(lambda x: x[\"item_id\"]).batch(1_000)\n","unique_item_ids = np.unique(np.concatenate(list(item_ids)))\n","item_descriptions = items_ds.map(lambda x: x[\"item_description\"]).batch(1_000)\n","unique_item_descriptions = np.unique(np.concatenate(list(item_descriptions)))"]},{"cell_type":"code","execution_count":19,"metadata":{},"outputs":[],"source":["class QueryItemModel(tf.keras.Model):\n","  embedding_dimension = 32\n","  def __init__(self):\n","    super().__init__()\n","\n","    max_tokens = 10_000\n","\n","    self.item_embedding = tf.keras.Sequential([\n","      tf.keras.layers.StringLookup(vocabulary=unique_item_ids, mask_token=None),\n","      tf.keras.layers.Embedding(len(unique_item_ids) + 1, self.embedding_dimension),\n","      tf.keras.layers.GRU(self.embedding_dimension),\n","    ])\n","\n","    self.description_text_embedding = tf.keras.Sequential([\n","      tf.keras.layers.TextVectorization(max_tokens=max_tokens),\n","      tf.keras.layers.Embedding(max_tokens, self.embedding_dimension, mask_zero=True),\n","      tf.keras.layers.GlobalAveragePooling1D(),\n","    ])\n","    self.description_vectorizer.adapt(unique_item_descriptions)\n","\n","  def call(self, features):\n","    return tf.concat([\n","        self.item_embedding(features[\"context_item_id\"]),\n","        self.description_text_embedding(features[\"context_item_description\"]),\n","    ], axis=1)"]},{"cell_type":"code","execution_count":20,"metadata":{"id":"ItnBlwlQZKeO"},"outputs":[],"source":["\n","class RetrievalModel(tfrs.Model):\n","    embedding_dimension = 32\n","    def __init__(self):\n","        super().__init__()\n","        self._query_model = QueryItemModel()\n","        self._candidate_model = tf.keras.Sequential([\n","            tf.keras.layers.StringLookup(vocabulary=unique_item_ids, mask_token=None),\n","            tf.keras.layers.Embedding(len(unique_item_ids) + 1, self.embedding_dimension)\n","            ])\n","        metrics = tfrs.metrics.FactorizedTopK(candidates=items_tf.batch(128).map(self._candidate_model))\n","        self._task = tfrs.tasks.Retrieval(metrics=metrics)\n","\n","    def compute_loss(self, features, training=False):\n","        item_history = {\n","            \"context_item_id\": features[\"context_item_id\"],\n","            \"context_item_description\": features[\"context_item_description\"]}   \n","        next_item_label = features[\"label_item_id\"]\n","\n","        query_embedding = self._query_model(item_history)       \n","        candidate_embedding = self._candidate_model(next_item_label)\n","\n","        return self._task(query_embedding, candidate_embedding, compute_metrics=not training)"]},{"cell_type":"code","execution_count":21,"metadata":{"id":"voqGGfVdZKeP"},"outputs":[],"source":["model = RetrievalModel()\n","model.compile(optimizer=tf.keras.optimizers.Adagrad(learning_rate=0.1))"]},{"cell_type":"code","execution_count":22,"metadata":{"id":"FTnWqXApZKeQ"},"outputs":[],"source":["cached_train = train_ds.shuffle(10_000).batch(12800).cache()\n","cached_test = test_ds.batch(2560).cache()"]},{"cell_type":"code","execution_count":23,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":375595,"status":"ok","timestamp":1660503356648,"user":{"displayName":"Anand Narwani","userId":"15456473225063541933"},"user_tz":240},"id":"KQxXOHpLZKeS","outputId":"0d37a932-ec25-4566-d957-2a7a12e33ef2"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/3\n"]},{"ename":"ValueError","evalue":"in user code:\n\n    File \"c:\\Users\\anand.HOME\\Anaconda3\\envs\\tf\\lib\\site-packages\\keras\\engine\\training.py\", line 1051, in train_function  *\n        return step_function(self, iterator)\n    File \"c:\\Users\\anand.HOME\\Anaconda3\\envs\\tf\\lib\\site-packages\\keras\\engine\\training.py\", line 1040, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\anand.HOME\\Anaconda3\\envs\\tf\\lib\\site-packages\\keras\\engine\\training.py\", line 1030, in run_step  **\n        outputs = model.train_step(data)\n    File \"c:\\Users\\anand.HOME\\Anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow_recommenders\\models\\base.py\", line 68, in train_step\n        loss = self.compute_loss(inputs, training=True)\n    File \"C:\\Users\\anand.HOME\\AppData\\Local\\Temp\\ipykernel_13424\\2786634238.py\", line 19, in compute_loss\n        query_embedding = self._query_model(item_history)\n    File \"c:\\Users\\anand.HOME\\Anaconda3\\envs\\tf\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"C:\\Users\\ANAND~1.HOM\\AppData\\Local\\Temp\\__autograph_generated_file_a217p3d.py\", line 12, in tf__call\n        retval_ = ag__.converted_call(ag__.ld(tf).concat, ([ag__.converted_call(ag__.ld(self).item_embedding, (ag__.ld(features)['context_item_id'],), None, fscope), ag__.converted_call(ag__.ld(self).description_text_embedding, (ag__.ld(features)['context_item_description'],), None, fscope)],), dict(axis=1), fscope)\n\n    ValueError: Exception encountered when calling layer \"query_item_model_2\" (type QueryItemModel).\n    \n    in user code:\n    \n        File \"C:\\Users\\anand.HOME\\AppData\\Local\\Temp\\ipykernel_13424\\1242551685.py\", line 27, in call  *\n            self.description_text_embedding(features[\"context_item_description\"]),\n        File \"c:\\Users\\anand.HOME\\Anaconda3\\envs\\tf\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 67, in error_handler  **\n            raise e.with_traceback(filtered_tb) from None\n        File \"c:\\Users\\anand.HOME\\Anaconda3\\envs\\tf\\lib\\site-packages\\keras\\layers\\preprocessing\\text_vectorization.py\", line 521, in _preprocess\n            raise ValueError(\n    \n        ValueError: Exception encountered when calling layer \"text_vectorization_2\" (type TextVectorization).\n        \n        When using `TextVectorization` to tokenize strings, the input rank must be 1 or the last shape dimension must be 1. Received: inputs.shape=(None, 10) with rank=2\n        \n        Call arguments received by layer \"text_vectorization_2\" (type TextVectorization):\n          • inputs=tf.Tensor(shape=(None, 10), dtype=string)\n    \n    \n    Call arguments received by layer \"query_item_model_2\" (type QueryItemModel):\n      • features={'context_item_id': 'tf.Tensor(shape=(None, 10), dtype=string)', 'context_item_description': 'tf.Tensor(shape=(None, 10), dtype=string)'}\n","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[1;32me:\\Documents\\Python\\retail_recommenders\\training\\retrieval_rich_model.ipynb Cell 8\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/e%3A/Documents/Python/retail_recommenders/training/retrieval_rich_model.ipynb#X10sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m model\u001b[39m.\u001b[39;49mfit(cached_train, epochs\u001b[39m=\u001b[39;49m\u001b[39m3\u001b[39;49m)\n","File \u001b[1;32mc:\\Users\\anand.HOME\\Anaconda3\\envs\\tf\\lib\\site-packages\\keras\\utils\\traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m---> 67\u001b[0m   \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[0;32m     68\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     69\u001b[0m   \u001b[39mdel\u001b[39;00m filtered_tb\n","File \u001b[1;32mC:\\Users\\ANAND~1.HOM\\AppData\\Local\\Temp\\__autograph_generated_fileazleq_vw.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     14\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m     retval_ \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(step_function), (ag__\u001b[39m.\u001b[39mld(\u001b[39mself\u001b[39m), ag__\u001b[39m.\u001b[39mld(iterator)), \u001b[39mNone\u001b[39;00m, fscope)\n\u001b[0;32m     16\u001b[0m \u001b[39mexcept\u001b[39;00m:\n\u001b[0;32m     17\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n","File \u001b[1;32mc:\\Users\\anand.HOME\\Anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow_recommenders\\models\\base.py:68\u001b[0m, in \u001b[0;36mModel.train_step\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[39m\"\"\"Custom train step using the `compute_loss` method.\"\"\"\u001b[39;00m\n\u001b[0;32m     67\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mGradientTape() \u001b[39mas\u001b[39;00m tape:\n\u001b[1;32m---> 68\u001b[0m   loss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcompute_loss(inputs, training\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m     70\u001b[0m   \u001b[39m# Handle regularization losses as well.\u001b[39;00m\n\u001b[0;32m     71\u001b[0m   regularization_loss \u001b[39m=\u001b[39m \u001b[39msum\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlosses)\n","\u001b[1;32me:\\Documents\\Python\\retail_recommenders\\training\\retrieval_rich_model.ipynb Cell 8\u001b[0m in \u001b[0;36mRetrievalModel.compute_loss\u001b[1;34m(self, features, training)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/Documents/Python/retail_recommenders/training/retrieval_rich_model.ipynb#X10sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m item_history \u001b[39m=\u001b[39m {\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/Documents/Python/retail_recommenders/training/retrieval_rich_model.ipynb#X10sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mcontext_item_id\u001b[39m\u001b[39m\"\u001b[39m: features[\u001b[39m\"\u001b[39m\u001b[39mcontext_item_id\u001b[39m\u001b[39m\"\u001b[39m],\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/Documents/Python/retail_recommenders/training/retrieval_rich_model.ipynb#X10sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mcontext_item_description\u001b[39m\u001b[39m\"\u001b[39m: features[\u001b[39m\"\u001b[39m\u001b[39mcontext_item_description\u001b[39m\u001b[39m\"\u001b[39m]}   \n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/Documents/Python/retail_recommenders/training/retrieval_rich_model.ipynb#X10sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m next_item_label \u001b[39m=\u001b[39m features[\u001b[39m\"\u001b[39m\u001b[39mlabel_item_id\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m---> <a href='vscode-notebook-cell:/e%3A/Documents/Python/retail_recommenders/training/retrieval_rich_model.ipynb#X10sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m query_embedding \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_query_model(item_history)       \n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/Documents/Python/retail_recommenders/training/retrieval_rich_model.ipynb#X10sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m candidate_embedding \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_candidate_model(next_item_label)\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/Documents/Python/retail_recommenders/training/retrieval_rich_model.ipynb#X10sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_task(query_embedding, candidate_embedding, compute_metrics\u001b[39m=\u001b[39m\u001b[39mnot\u001b[39;00m training)\n","File \u001b[1;32mC:\\Users\\ANAND~1.HOM\\AppData\\Local\\Temp\\__autograph_generated_file_a217p3d.py:12\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__call\u001b[1;34m(self, features)\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     11\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m---> 12\u001b[0m     retval_ \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(tf)\u001b[39m.\u001b[39mconcat, ([ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(\u001b[39mself\u001b[39m)\u001b[39m.\u001b[39mitem_embedding, (ag__\u001b[39m.\u001b[39mld(features)[\u001b[39m'\u001b[39m\u001b[39mcontext_item_id\u001b[39m\u001b[39m'\u001b[39m],), \u001b[39mNone\u001b[39;00m, fscope), ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(\u001b[39mself\u001b[39m)\u001b[39m.\u001b[39mdescription_text_embedding, (ag__\u001b[39m.\u001b[39mld(features)[\u001b[39m'\u001b[39m\u001b[39mcontext_item_description\u001b[39m\u001b[39m'\u001b[39m],), \u001b[39mNone\u001b[39;00m, fscope)],), \u001b[39mdict\u001b[39m(axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m), fscope)\n\u001b[0;32m     13\u001b[0m \u001b[39mexcept\u001b[39;00m:\n\u001b[0;32m     14\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n","\u001b[1;31mValueError\u001b[0m: in user code:\n\n    File \"c:\\Users\\anand.HOME\\Anaconda3\\envs\\tf\\lib\\site-packages\\keras\\engine\\training.py\", line 1051, in train_function  *\n        return step_function(self, iterator)\n    File \"c:\\Users\\anand.HOME\\Anaconda3\\envs\\tf\\lib\\site-packages\\keras\\engine\\training.py\", line 1040, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\anand.HOME\\Anaconda3\\envs\\tf\\lib\\site-packages\\keras\\engine\\training.py\", line 1030, in run_step  **\n        outputs = model.train_step(data)\n    File \"c:\\Users\\anand.HOME\\Anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow_recommenders\\models\\base.py\", line 68, in train_step\n        loss = self.compute_loss(inputs, training=True)\n    File \"C:\\Users\\anand.HOME\\AppData\\Local\\Temp\\ipykernel_13424\\2786634238.py\", line 19, in compute_loss\n        query_embedding = self._query_model(item_history)\n    File \"c:\\Users\\anand.HOME\\Anaconda3\\envs\\tf\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"C:\\Users\\ANAND~1.HOM\\AppData\\Local\\Temp\\__autograph_generated_file_a217p3d.py\", line 12, in tf__call\n        retval_ = ag__.converted_call(ag__.ld(tf).concat, ([ag__.converted_call(ag__.ld(self).item_embedding, (ag__.ld(features)['context_item_id'],), None, fscope), ag__.converted_call(ag__.ld(self).description_text_embedding, (ag__.ld(features)['context_item_description'],), None, fscope)],), dict(axis=1), fscope)\n\n    ValueError: Exception encountered when calling layer \"query_item_model_2\" (type QueryItemModel).\n    \n    in user code:\n    \n        File \"C:\\Users\\anand.HOME\\AppData\\Local\\Temp\\ipykernel_13424\\1242551685.py\", line 27, in call  *\n            self.description_text_embedding(features[\"context_item_description\"]),\n        File \"c:\\Users\\anand.HOME\\Anaconda3\\envs\\tf\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 67, in error_handler  **\n            raise e.with_traceback(filtered_tb) from None\n        File \"c:\\Users\\anand.HOME\\Anaconda3\\envs\\tf\\lib\\site-packages\\keras\\layers\\preprocessing\\text_vectorization.py\", line 521, in _preprocess\n            raise ValueError(\n    \n        ValueError: Exception encountered when calling layer \"text_vectorization_2\" (type TextVectorization).\n        \n        When using `TextVectorization` to tokenize strings, the input rank must be 1 or the last shape dimension must be 1. Received: inputs.shape=(None, 10) with rank=2\n        \n        Call arguments received by layer \"text_vectorization_2\" (type TextVectorization):\n          • inputs=tf.Tensor(shape=(None, 10), dtype=string)\n    \n    \n    Call arguments received by layer \"query_item_model_2\" (type QueryItemModel):\n      • features={'context_item_id': 'tf.Tensor(shape=(None, 10), dtype=string)', 'context_item_description': 'tf.Tensor(shape=(None, 10), dtype=string)'}\n"]}],"source":["model.fit(cached_train, epochs=3)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":923963,"status":"ok","timestamp":1660504298491,"user":{"displayName":"Anand Narwani","userId":"15456473225063541933"},"user_tz":240},"id":"8IKk9JhOZKeT","outputId":"8ec19960-0e4d-4503-8f2e-94bc04d6de4d"},"outputs":[],"source":["model.evaluate(cached_test, return_dict=True)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["for x in items_ds.take(5).as_numpy_iterator():\n","  pprint.pprint(x)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":20367,"status":"ok","timestamp":1660506016473,"user":{"displayName":"Anand Narwani","userId":"15456473225063541933"},"user_tz":240},"id":"1wJ_SheQZKeU","outputId":"37fcafef-92ee-4bdf-e68f-15b06ebb690d"},"outputs":[],"source":["# Create a model that takes in raw query features, and\n","index = tfrs.layers.factorized_top_k.BruteForce(model._query_model)\n","# recommends movies out of the entire movies dataset.\n","index.index_from_dataset(\n","  tf.data.Dataset.zip((items.batch(100), items.batch(100).map(model._candidate_model)))\n",")\n","_ = index(tf.constant(['139716','35287','142953','132041','','','','','','',],shape=(1,10,1)))\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"i6FXFu8gZKeV"},"outputs":[],"source":["foo, titles = index(tf.constant(['139716','35287','142953','132041','','','','','','',],shape=(1,10,1)))\n","print(foo)\n","print(titles)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1659360958291,"user":{"displayName":"Anand Narwani","userId":"15456473225063541933"},"user_tz":240},"id":"MXECG-kQZKeV","outputId":"fe894f29-c004-41d5-f0ab-6fecc040cb7c"},"outputs":[],"source":["path = '../data/retrieval_model'\n","tf.saved_model.save(index, path)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JChlbQ4JZKeX"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QL1aXh-Un5Ph"},"outputs":[],"source":["foo, titles = loaded(tf.constant(['139716','35287','142953','132041','','','','','','',],shape=(1,10,1)))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":293,"status":"ok","timestamp":1659361055767,"user":{"displayName":"Anand Narwani","userId":"15456473225063541933"},"user_tz":240},"id":"OlY8qnJsoCse","outputId":"79360e63-d67b-4561-dd8d-ac8f400e47e3"},"outputs":[],"source":["print (titles)"]}],"metadata":{"colab":{"name":"sequential_recommender.ipynb","provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3.9.12 ('tf')","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.12"},"vscode":{"interpreter":{"hash":"d7f156ea84fdc221bcc828ba074462c25de1a00a239b7857dab945319d42b0e1"}}},"nbformat":4,"nbformat_minor":0}
