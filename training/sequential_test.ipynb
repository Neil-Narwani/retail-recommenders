{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pprint\n",
    "import tempfile\n",
    "\n",
    "from typing import Dict, Text\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import tensorflow_recommenders as tfrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_filename = \"./data/samples/train_transactions_gt2018.tfrecord\"\n",
    "train = tf.data.TFRecordDataset(train_filename)\n",
    "\n",
    "test_filename = \"./data/samples/test_transactions_gt2018.tfrecord\"\n",
    "test = tf.data.TFRecordDataset(test_filename)\n",
    "\n",
    "feature_description = {\n",
    "    'context_item_id': tf.io.FixedLenFeature([10], tf.int64, default_value=np.repeat(0, 10)),\n",
    "    'context_item_quantity': tf.io.FixedLenFeature([10], tf.float32, default_value=np.repeat(0, 10)),\n",
    "    'context_item_price': tf.io.FixedLenFeature([10], tf.float32, default_value=np.repeat(0, 10)),\n",
    "    'context_department_id': tf.io.FixedLenFeature([10], tf.int64, default_value=np.repeat(0, 10)),\n",
    "    'context_discount_id': tf.io.FixedLenFeature([10], tf.int64, default_value=np.repeat(0, 10)),\n",
    "    'context_return_id': tf.io.FixedLenFeature([10], tf.int64, default_value=np.repeat(0, 10)),   \n",
    "    'label_item_id': tf.io.FixedLenFeature([1], tf.int64, default_value=0),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _parse_function(example_proto):\n",
    "  return tf.io.parse_single_example(example_proto, feature_description)\n",
    "\n",
    "train_ds = train.map(_parse_function).map(lambda x: {\n",
    "    \"context_item_id\": tf.strings.as_string(x[\"context_item_id\"]),\n",
    "    \"label_item_id\": tf.strings.as_string(x[\"label_item_id\"])\n",
    "})\n",
    "\n",
    "test_ds = test.map(_parse_function).map(lambda x: {\n",
    "    \"context_item_id\": tf.strings.as_string(x[\"context_item_id\"]),\n",
    "    \"label_item_id\": tf.strings.as_string(x[\"label_item_id\"])\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'context_item_id': array([b'51484', b'14856', b'30961', b'30961', b'114343', b'51484',\n",
      "       b'88698', b'96369', b'96382', b'51484'], dtype=object),\n",
      " 'label_item_id': array([b'31287'], dtype=object)}\n"
     ]
    }
   ],
   "source": [
    "for x in train_ds.take(1).as_numpy_iterator():\n",
    "  pprint.pprint(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "items_filename = \"./web/data/samples/items.tfrecord\"\n",
    "items_tf = tf.data.TFRecordDataset(items_filename)\n",
    "item_feature_description = {\n",
    "    'item_id': tf.io.FixedLenFeature([1], tf.int64, default_value=0),\n",
    "    'item_description': tf.io.FixedLenFeature([1], tf.string, default_value='None')}\n",
    "def item_parse_function(example_proto):\n",
    "  return tf.io.parse_single_example(example_proto, item_feature_description)\n",
    "\n",
    "items_ds = items_tf.map(item_parse_function).map(lambda x: {\n",
    "    \"item_id\": tf.strings.as_string(x[\"item_id\"]),\n",
    "    \"item_description\": x[\"item_description\"],\n",
    "})\n",
    "items = items_ds.map(lambda x: x[\"item_id\"])\n",
    "item_ids = items.batch(1_000)\n",
    "unique_item_ids = np.unique(np.concatenate(list(item_ids)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dimension = 32\n",
    "\n",
    "query_model = tf.keras.Sequential([\n",
    "    tf.keras.layers.StringLookup(\n",
    "      vocabulary=unique_item_ids, mask_token=None),\n",
    "    tf.keras.layers.Embedding(len(unique_item_ids) + 1, embedding_dimension), \n",
    "    tf.keras.layers.GRU(embedding_dimension),\n",
    "])\n",
    "\n",
    "candidate_model = tf.keras.Sequential([\n",
    "  tf.keras.layers.StringLookup(\n",
    "      vocabulary=unique_item_ids, mask_token=None),\n",
    "  tf.keras.layers.Embedding(len(unique_item_ids) + 1, embedding_dimension)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = tfrs.metrics.FactorizedTopK(\n",
    "  candidates=items_tf.batch(128).map(candidate_model)\n",
    ")\n",
    "\n",
    "task = tfrs.tasks.Retrieval(\n",
    "  metrics=metrics\n",
    ")\n",
    "\n",
    "class MyModel(tfrs.Model):\n",
    "\n",
    "    def __init__(self, query_model, candidate_model):\n",
    "        super().__init__()\n",
    "        self._query_model = query_model\n",
    "        self._candidate_model = candidate_model\n",
    "\n",
    "        self._task = task\n",
    "\n",
    "    def compute_loss(self, features, training=False):\n",
    "        watch_history = features[\"context_item_id\"]\n",
    "        watch_next_label = features[\"label_item_id\"]\n",
    "\n",
    "        query_embedding = self._query_model(watch_history)       \n",
    "        candidate_embedding = self._candidate_model(watch_next_label)\n",
    "\n",
    "        return self._task(query_embedding, candidate_embedding, compute_metrics=not training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MyModel(query_model, candidate_model)\n",
    "model.compile(optimizer=tf.keras.optimizers.Adagrad(learning_rate=0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "cached_train = train_ds.shuffle(10_000).batch(12800).cache()\n",
    "cached_test = test_ds.batch(2560).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "34/34 [==============================] - 20s 403ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 112796.9858 - regularization_loss: 0.0000e+00 - total_loss: 112796.9858\n",
      "Epoch 2/3\n",
      "34/34 [==============================] - 4s 107ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 103247.6742 - regularization_loss: 0.0000e+00 - total_loss: 103247.6742\n",
      "Epoch 3/3\n",
      "34/34 [==============================] - 4s 106ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 98140.1726 - regularization_loss: 0.0000e+00 - total_loss: 98140.1726\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x235f22daca0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(cached_train, epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - 481s 11s/step - factorized_top_k/top_1_categorical_accuracy: 0.8846 - factorized_top_k/top_5_categorical_accuracy: 0.8846 - factorized_top_k/top_10_categorical_accuracy: 0.8846 - factorized_top_k/top_50_categorical_accuracy: 0.8846 - factorized_top_k/top_100_categorical_accuracy: 0.8846 - loss: 16154.2675 - regularization_loss: 0.0000e+00 - total_loss: 16154.2675\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'factorized_top_k/top_1_categorical_accuracy': 0.8845945000648499,\n",
       " 'factorized_top_k/top_5_categorical_accuracy': 0.8845945000648499,\n",
       " 'factorized_top_k/top_10_categorical_accuracy': 0.8845945000648499,\n",
       " 'factorized_top_k/top_50_categorical_accuracy': 0.8845945000648499,\n",
       " 'factorized_top_k/top_100_categorical_accuracy': 0.8845945000648499,\n",
       " 'loss': 412.1374206542969,\n",
       " 'regularization_loss': 0,\n",
       " 'total_loss': 412.1374206542969}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(cached_test, return_dict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow_recommenders.layers.factorized_top_k.BruteForce object at 0x0000023739B8B1C0>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as query_with_exclusions, gru_cell_layer_call_fn, gru_cell_layer_call_and_return_conditional_losses while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./web/data/samples/saved_model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./web/data/samples/saved_model\\assets\n"
     ]
    }
   ],
   "source": [
    "# Create a model that takes in raw query features, and\n",
    "index = tfrs.layers.factorized_top_k.BruteForce(model._query_model)\n",
    "# recommends movies out of the entire movies dataset.\n",
    "index.index_from_dataset(\n",
    "  tf.data.Dataset.zip((items.batch(100), items.batch(100).map(model._candidate_model)))\n",
    ")\n",
    "path = './web/data/samples/saved_model'\n",
    "tf.saved_model.save(index, path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "foo, titles = index(tf.constant(['139716','35287','142953','132041','','','','','','',],shape=(1,10,1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[3.259811  3.1711054 3.159664  3.1514008 3.115191  3.0871491 3.0802324\n",
      "  3.0752077 3.0517814 3.0282812]], shape=(1, 10), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[[b'29822']\n",
      "  [b'145973']\n",
      "  [b'132418']\n",
      "  [b'114617']\n",
      "  [b'73940']\n",
      "  [b'99887']\n",
      "  [b'84706']\n",
      "  [b'126377']\n",
      "  [b'31124']\n",
      "  [b'151992']]], shape=(1, 10, 1), dtype=string)\n"
     ]
    }
   ],
   "source": [
    "print(foo)\n",
    "print(titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[3.3212721 3.2121694 3.134917  3.1190243 3.1052196 3.0620832 3.0236504\n",
      "  3.0063984 2.9986353 2.9633884]], shape=(1, 10), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[[b'73343']\n",
      "  [b'151931']\n",
      "  [b'133325']\n",
      "  [b'49788']\n",
      "  [b'76912']\n",
      "  [b'145911']\n",
      "  [b'107808']\n",
      "  [b'28549']\n",
      "  [b'128225']\n",
      "  [b'133326']]], shape=(1, 10, 1), dtype=string)\n"
     ]
    }
   ],
   "source": [
    "foo, titles = index(tf.constant(['95801','91520','37133','57218','','','','','','',],shape=(1,10,1)))\n",
    "print(foo)\n",
    "print(titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[b'29822', b'145973', b'132418', b'114617', b'73940']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titles.numpy().flatten().tolist()[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <__main__.MyModel object at 0x000002A7D0578280>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <__main__.MyModel object at 0x000002A7D0578280>, because it is not built.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Model <__main__.MyModel object at 0x000002A7D0578280> cannot be saved either because the input shape is not available or because the forward pass of the model is not defined.To define a forward pass, please override `Model.call()`. To specify an input shape, either call `build(input_shape)` directly, or call the model on actual data using `Model()`, `Model.fit()`, or `Model.predict()`. If you have a custom training step, please make sure to invoke the forward pass in train step through `Model.__call__`, i.e. `model(inputs)`, as opposed to `model.call()`.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [125]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeras\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdata/save2\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\tf\\lib\\site-packages\\keras\\utils\\traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m---> 67\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     69\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\tf\\lib\\site-packages\\keras\\saving\\saving_utils.py:93\u001b[0m, in \u001b[0;36mraise_model_input_error\u001b[1;34m(model)\u001b[0m\n\u001b[0;32m     86\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m     87\u001b[0m       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mModel \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m cannot be saved because the input shape is not \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     88\u001b[0m       \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mavailable. Please specify an input shape either by calling \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     89\u001b[0m       \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m`build(input_shape)` directly, or by calling the model on actual \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     90\u001b[0m       \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata using `Model()`, `Model.fit()`, or `Model.predict()`.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     92\u001b[0m \u001b[38;5;66;03m# If the model is not a `Sequential`, it is intended to be a subclassed model.\u001b[39;00m\n\u001b[1;32m---> 93\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m     94\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mModel \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m cannot be saved either because the input shape is not \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     95\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mavailable or because the forward pass of the model is not defined.\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     96\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTo define a forward pass, please override `Model.call()`. To specify \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     97\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124man input shape, either call `build(input_shape)` directly, or call \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     98\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mthe model on actual data using `Model()`, `Model.fit()`, or \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     99\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m`Model.predict()`. If you have a custom training step, please make \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    100\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msure to invoke the forward pass in train step through \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    101\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m`Model.__call__`, i.e. `model(inputs)`, as opposed to `model.call()`.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: Model <__main__.MyModel object at 0x000002A7D0578280> cannot be saved either because the input shape is not available or because the forward pass of the model is not defined.To define a forward pass, please override `Model.call()`. To specify an input shape, either call `build(input_shape)` directly, or call the model on actual data using `Model()`, `Model.fit()`, or `Model.predict()`. If you have a custom training step, please make sure to invoke the forward pass in train step through `Model.__call__`, i.e. `model(inputs)`, as opposed to `model.call()`."
     ]
    }
   ],
   "source": [
    "tf.keras.models.save_model(model, 'data/save2')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit (windows store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "92b81673b6b4f2f7eddec753ebdcac00d7ea36aedc49ab576bc6a6c668bf2f2a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
