{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pprint\n",
    "import tempfile\n",
    "\n",
    "from typing import Dict, Text\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import tensorflow_recommenders as tfrs\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_filename = \"../data/samples/train_user_item_transactions.tfrecord\"\n",
    "train = tf.data.TFRecordDataset(train_filename)\n",
    "\n",
    "test_filename = \"../data/samples/test_user_item_transactions.tfrecord\"\n",
    "\n",
    "test = tf.data.TFRecordDataset(test_filename)\n",
    "feature_description = {\n",
    "    'user_id': tf.io.FixedLenFeature([], tf.int64, default_value=0),\n",
    "    'item_id': tf.io.FixedLenFeature([], tf.int64, default_value=0),\n",
    "    'item_trantime' : tf.io.FixedLenFeature([], tf.int64, default_value=0),\n",
    "    'item_price': tf.io.FixedLenFeature([], tf.float32, default_value=0.0),\n",
    "    'item_fullprice': tf.io.FixedLenFeature([], tf.float32, default_value=0.0),\n",
    "    'item_quantity': tf.io.FixedLenFeature([], tf.float32, default_value=0.0),\n",
    "    'department_id': tf.io.FixedLenFeature([], tf.int64, default_value=0),\n",
    "    'return_id': tf.io.FixedLenFeature([], tf.int64, default_value=0),                \n",
    "    'discount_id': tf.io.FixedLenFeature([], tf.int64, default_value=0),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _parse_function(example_proto):\n",
    "  return tf.io.parse_single_example(example_proto, feature_description)\n",
    "\n",
    "train_ds = train.map(_parse_function).map(lambda x: {\n",
    "    'user_id': x['user_id'],\n",
    "    'item_id': x['item_id'],\n",
    "})\n",
    "\n",
    "test_ds = test.map(_parse_function).map(lambda x: {\n",
    "    'user_id': x['user_id'],\n",
    "    'item_id': x['item_id'],\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "items_filename = '../data/samples/items.tfrecord'\n",
    "items_tf = tf.data.TFRecordDataset(items_filename)\n",
    "item_feature_description = {\n",
    "    'item_id': tf.io.FixedLenFeature([], tf.int64, default_value=0)\n",
    "}\n",
    "\n",
    "def item_parse_function(example_proto):\n",
    "  return tf.io.parse_single_example(example_proto, item_feature_description)\n",
    "\n",
    "items_ds = items_tf.map(item_parse_function).map(lambda x: {\n",
    "    'item_id': x['item_id']\n",
    "})\n",
    "item_ids = items_ds.map(lambda x: x['item_id'])\n",
    "unique_item_ids = np.unique(np.concatenate(list(item_ids.batch(1000))))\n",
    "\n",
    "customers_filename = '../data/samples/customers.tfrecord'\n",
    "customers_tf = tf.data.TFRecordDataset(customers_filename)\n",
    "customer_feature_description = {\n",
    "  'user_id' : tf.io.FixedLenFeature([], tf.int64, default_value=0),\n",
    "  'zip_code' : tf.io.FixedLenFeature([], tf.string, default_value='None'),\n",
    "  'total_visits' : tf.io.FixedLenFeature([], tf.int64, default_value=0),\n",
    "  'total_sales' : tf.io.FixedLenFeature([], tf.float32, default_value=0.0),\n",
    "  'total_savings' : tf.io.FixedLenFeature([], tf.float32, default_value=0.0)\n",
    "}\n",
    "\n",
    "def customer_parse_function(example_proto):\n",
    "  return tf.io.parse_single_example(example_proto, customer_feature_description)\n",
    "\n",
    "customers_ds = customers_tf.map(customer_parse_function).map(lambda x: {\n",
    "  'user_id' : x['user_id'],\n",
    "})\n",
    "customer_ids = customers_ds.map(lambda x: x['user_id'])\n",
    "unique_customer_ids = np.unique(np.concatenate(list(customer_ids.batch(1000))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dimension = 32\n",
    "\n",
    "user_model = tf.keras.Sequential([\n",
    "  tf.keras.layers.IntegerLookup(vocabulary=unique_customer_ids, mask_token=None),\n",
    "  # We add an additional embedding to account for unknown tokens.\n",
    "  tf.keras.layers.Embedding(len(unique_customer_ids) + 1, embedding_dimension)\n",
    "])\n",
    "\n",
    "item_model = tf.keras.Sequential([\n",
    "  tf.keras.layers.IntegerLookup(vocabulary=unique_item_ids, mask_token=None),\n",
    "  tf.keras.layers.Embedding(len(unique_item_ids) + 1, embedding_dimension)\n",
    "])\n",
    "\n",
    "metrics = tfrs.metrics.FactorizedTopK(candidates=item_ids.batch(12800).map(item_model))\n",
    "task = tfrs.tasks.Retrieval(metrics=metrics)\n",
    "\n",
    "class MovielensModel(tfrs.Model):\n",
    "\n",
    "  def __init__(self, user_model, item_model):\n",
    "    super().__init__()\n",
    "    self.item_model: tf.keras.Model = item_model\n",
    "    self.user_model: tf.keras.Model = user_model\n",
    "    self.task: tf.keras.layers.Layer = task\n",
    "\n",
    "  def compute_loss(self, features: Dict[Text, tf.Tensor], training=False) -> tf.Tensor:\n",
    "    # We pick out the user features and pass them into the user model.\n",
    "    user_embeddings = self.user_model(features['user_id'])\n",
    "    # And pick out the movie features and pass them into the movie model,\n",
    "    # getting embeddings back.\n",
    "    positive_item_embeddings = self.item_model(features['item_id'])\n",
    "\n",
    "    # The task computes the loss and the metrics.\n",
    "    return self.task(user_embeddings, positive_item_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MovielensModel(user_model, item_model)\n",
    "model.compile(optimizer=tf.keras.optimizers.Adagrad(learning_rate=0.1))\n",
    "log_dir = \"../logs/fit\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cached_train = train_ds.shuffle(10_000).batch(6400).cache()\n",
    "cached_test = test_ds.batch(2560).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/36\n",
      "187/187 [==============================] - 382s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.0074 - factorized_top_k/top_5_categorical_accuracy: 0.0588 - factorized_top_k/top_10_categorical_accuracy: 0.0804 - factorized_top_k/top_50_categorical_accuracy: 0.1495 - factorized_top_k/top_100_categorical_accuracy: 0.1924 - loss: 53162.5028 - regularization_loss: 0.0000e+00 - total_loss: 53162.5028 - val_factorized_top_k/top_1_categorical_accuracy: 0.0297 - val_factorized_top_k/top_5_categorical_accuracy: 0.0917 - val_factorized_top_k/top_10_categorical_accuracy: 0.1220 - val_factorized_top_k/top_50_categorical_accuracy: 0.2125 - val_factorized_top_k/top_100_categorical_accuracy: 0.2661 - val_loss: 12302.7529 - val_regularization_loss: 0.0000e+00 - val_total_loss: 12302.7529\n",
      "Epoch 2/36\n",
      "187/187 [==============================] - 335s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.0141 - factorized_top_k/top_5_categorical_accuracy: 0.1334 - factorized_top_k/top_10_categorical_accuracy: 0.1770 - factorized_top_k/top_50_categorical_accuracy: 0.2949 - factorized_top_k/top_100_categorical_accuracy: 0.3582 - loss: 47929.9182 - regularization_loss: 0.0000e+00 - total_loss: 47929.9182 - val_factorized_top_k/top_1_categorical_accuracy: 0.0333 - val_factorized_top_k/top_5_categorical_accuracy: 0.1080 - val_factorized_top_k/top_10_categorical_accuracy: 0.1434 - val_factorized_top_k/top_50_categorical_accuracy: 0.2431 - val_factorized_top_k/top_100_categorical_accuracy: 0.2985 - val_loss: 11644.4395 - val_regularization_loss: 0.0000e+00 - val_total_loss: 11644.4395\n",
      "Epoch 3/36\n",
      "187/187 [==============================] - 346s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.0153 - factorized_top_k/top_5_categorical_accuracy: 0.1678 - factorized_top_k/top_10_categorical_accuracy: 0.2216 - factorized_top_k/top_50_categorical_accuracy: 0.3570 - factorized_top_k/top_100_categorical_accuracy: 0.4255 - loss: 44758.6313 - regularization_loss: 0.0000e+00 - total_loss: 44758.6313 - val_factorized_top_k/top_1_categorical_accuracy: 0.0329 - val_factorized_top_k/top_5_categorical_accuracy: 0.1112 - val_factorized_top_k/top_10_categorical_accuracy: 0.1475 - val_factorized_top_k/top_50_categorical_accuracy: 0.2496 - val_factorized_top_k/top_100_categorical_accuracy: 0.3045 - val_loss: 11400.2939 - val_regularization_loss: 0.0000e+00 - val_total_loss: 11400.2939\n",
      "Epoch 4/36\n",
      "187/187 [==============================] - 348s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.0145 - factorized_top_k/top_5_categorical_accuracy: 0.1846 - factorized_top_k/top_10_categorical_accuracy: 0.2437 - factorized_top_k/top_50_categorical_accuracy: 0.3872 - factorized_top_k/top_100_categorical_accuracy: 0.4584 - loss: 42770.8889 - regularization_loss: 0.0000e+00 - total_loss: 42770.8889 - val_factorized_top_k/top_1_categorical_accuracy: 0.0322 - val_factorized_top_k/top_5_categorical_accuracy: 0.1107 - val_factorized_top_k/top_10_categorical_accuracy: 0.1469 - val_factorized_top_k/top_50_categorical_accuracy: 0.2492 - val_factorized_top_k/top_100_categorical_accuracy: 0.3038 - val_loss: 11309.5195 - val_regularization_loss: 0.0000e+00 - val_total_loss: 11309.5195\n",
      "Epoch 5/36\n",
      "187/187 [==============================] - 345s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.0138 - factorized_top_k/top_5_categorical_accuracy: 0.1934 - factorized_top_k/top_10_categorical_accuracy: 0.2558 - factorized_top_k/top_50_categorical_accuracy: 0.4048 - factorized_top_k/top_100_categorical_accuracy: 0.4771 - loss: 41414.4319 - regularization_loss: 0.0000e+00 - total_loss: 41414.4319 - val_factorized_top_k/top_1_categorical_accuracy: 0.0319 - val_factorized_top_k/top_5_categorical_accuracy: 0.1090 - val_factorized_top_k/top_10_categorical_accuracy: 0.1454 - val_factorized_top_k/top_50_categorical_accuracy: 0.2464 - val_factorized_top_k/top_100_categorical_accuracy: 0.3014 - val_loss: 11287.7852 - val_regularization_loss: 0.0000e+00 - val_total_loss: 11287.7852\n",
      "Epoch 6/36\n",
      "187/187 [==============================] - 344s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.0135 - factorized_top_k/top_5_categorical_accuracy: 0.1986 - factorized_top_k/top_10_categorical_accuracy: 0.2634 - factorized_top_k/top_50_categorical_accuracy: 0.4160 - factorized_top_k/top_100_categorical_accuracy: 0.4889 - loss: 40428.5761 - regularization_loss: 0.0000e+00 - total_loss: 40428.5761 - val_factorized_top_k/top_1_categorical_accuracy: 0.0301 - val_factorized_top_k/top_5_categorical_accuracy: 0.1070 - val_factorized_top_k/top_10_categorical_accuracy: 0.1434 - val_factorized_top_k/top_50_categorical_accuracy: 0.2441 - val_factorized_top_k/top_100_categorical_accuracy: 0.2985 - val_loss: 11301.0518 - val_regularization_loss: 0.0000e+00 - val_total_loss: 11301.0518\n",
      "Epoch 7/36\n",
      "187/187 [==============================] - 328s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.0136 - factorized_top_k/top_5_categorical_accuracy: 0.2021 - factorized_top_k/top_10_categorical_accuracy: 0.2684 - factorized_top_k/top_50_categorical_accuracy: 0.4233 - factorized_top_k/top_100_categorical_accuracy: 0.4969 - loss: 39678.8607 - regularization_loss: 0.0000e+00 - total_loss: 39678.8607 - val_factorized_top_k/top_1_categorical_accuracy: 0.0295 - val_factorized_top_k/top_5_categorical_accuracy: 0.1053 - val_factorized_top_k/top_10_categorical_accuracy: 0.1413 - val_factorized_top_k/top_50_categorical_accuracy: 0.2413 - val_factorized_top_k/top_100_categorical_accuracy: 0.2954 - val_loss: 11332.4805 - val_regularization_loss: 0.0000e+00 - val_total_loss: 11332.4805\n",
      "Epoch 8/36\n",
      "187/187 [==============================] - 331s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.0138 - factorized_top_k/top_5_categorical_accuracy: 0.2042 - factorized_top_k/top_10_categorical_accuracy: 0.2718 - factorized_top_k/top_50_categorical_accuracy: 0.4287 - factorized_top_k/top_100_categorical_accuracy: 0.5026 - loss: 39088.7553 - regularization_loss: 0.0000e+00 - total_loss: 39088.7553 - val_factorized_top_k/top_1_categorical_accuracy: 0.0291 - val_factorized_top_k/top_5_categorical_accuracy: 0.1026 - val_factorized_top_k/top_10_categorical_accuracy: 0.1392 - val_factorized_top_k/top_50_categorical_accuracy: 0.2384 - val_factorized_top_k/top_100_categorical_accuracy: 0.2923 - val_loss: 11372.6514 - val_regularization_loss: 0.0000e+00 - val_total_loss: 11372.6514\n",
      "Epoch 9/36\n",
      "187/187 [==============================] - 333s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.0141 - factorized_top_k/top_5_categorical_accuracy: 0.2057 - factorized_top_k/top_10_categorical_accuracy: 0.2741 - factorized_top_k/top_50_categorical_accuracy: 0.4328 - factorized_top_k/top_100_categorical_accuracy: 0.5070 - loss: 38611.6463 - regularization_loss: 0.0000e+00 - total_loss: 38611.6463 - val_factorized_top_k/top_1_categorical_accuracy: 0.0282 - val_factorized_top_k/top_5_categorical_accuracy: 0.1011 - val_factorized_top_k/top_10_categorical_accuracy: 0.1376 - val_factorized_top_k/top_50_categorical_accuracy: 0.2361 - val_factorized_top_k/top_100_categorical_accuracy: 0.2896 - val_loss: 11416.3164 - val_regularization_loss: 0.0000e+00 - val_total_loss: 11416.3164\n",
      "Epoch 10/36\n",
      "187/187 [==============================] - 331s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.0144 - factorized_top_k/top_5_categorical_accuracy: 0.2066 - factorized_top_k/top_10_categorical_accuracy: 0.2758 - factorized_top_k/top_50_categorical_accuracy: 0.4356 - factorized_top_k/top_100_categorical_accuracy: 0.5103 - loss: 38217.6043 - regularization_loss: 0.0000e+00 - total_loss: 38217.6043 - val_factorized_top_k/top_1_categorical_accuracy: 0.0272 - val_factorized_top_k/top_5_categorical_accuracy: 0.0995 - val_factorized_top_k/top_10_categorical_accuracy: 0.1356 - val_factorized_top_k/top_50_categorical_accuracy: 0.2342 - val_factorized_top_k/top_100_categorical_accuracy: 0.2873 - val_loss: 11460.6191 - val_regularization_loss: 0.0000e+00 - val_total_loss: 11460.6191\n",
      "Epoch 11/36\n",
      "187/187 [==============================] - 331s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.0148 - factorized_top_k/top_5_categorical_accuracy: 0.2071 - factorized_top_k/top_10_categorical_accuracy: 0.2770 - factorized_top_k/top_50_categorical_accuracy: 0.4381 - factorized_top_k/top_100_categorical_accuracy: 0.5131 - loss: 37886.4614 - regularization_loss: 0.0000e+00 - total_loss: 37886.4614 - val_factorized_top_k/top_1_categorical_accuracy: 0.0269 - val_factorized_top_k/top_5_categorical_accuracy: 0.0979 - val_factorized_top_k/top_10_categorical_accuracy: 0.1338 - val_factorized_top_k/top_50_categorical_accuracy: 0.2321 - val_factorized_top_k/top_100_categorical_accuracy: 0.2852 - val_loss: 11504.0791 - val_regularization_loss: 0.0000e+00 - val_total_loss: 11504.0791\n",
      "Epoch 12/36\n",
      "187/187 [==============================] - 377s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.0153 - factorized_top_k/top_5_categorical_accuracy: 0.2072 - factorized_top_k/top_10_categorical_accuracy: 0.2778 - factorized_top_k/top_50_categorical_accuracy: 0.4403 - factorized_top_k/top_100_categorical_accuracy: 0.5155 - loss: 37604.0936 - regularization_loss: 0.0000e+00 - total_loss: 37604.0936 - val_factorized_top_k/top_1_categorical_accuracy: 0.0262 - val_factorized_top_k/top_5_categorical_accuracy: 0.0968 - val_factorized_top_k/top_10_categorical_accuracy: 0.1323 - val_factorized_top_k/top_50_categorical_accuracy: 0.2303 - val_factorized_top_k/top_100_categorical_accuracy: 0.2831 - val_loss: 11545.9795 - val_regularization_loss: 0.0000e+00 - val_total_loss: 11545.9795\n",
      "Epoch 13/36\n",
      "187/187 [==============================] - 324s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.0158 - factorized_top_k/top_5_categorical_accuracy: 0.2073 - factorized_top_k/top_10_categorical_accuracy: 0.2784 - factorized_top_k/top_50_categorical_accuracy: 0.4421 - factorized_top_k/top_100_categorical_accuracy: 0.5173 - loss: 37360.2686 - regularization_loss: 0.0000e+00 - total_loss: 37360.2686 - val_factorized_top_k/top_1_categorical_accuracy: 0.0257 - val_factorized_top_k/top_5_categorical_accuracy: 0.0958 - val_factorized_top_k/top_10_categorical_accuracy: 0.1312 - val_factorized_top_k/top_50_categorical_accuracy: 0.2289 - val_factorized_top_k/top_100_categorical_accuracy: 0.2811 - val_loss: 11586.0205 - val_regularization_loss: 0.0000e+00 - val_total_loss: 11586.0205\n",
      "Epoch 14/36\n",
      "187/187 [==============================] - 322s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.0164 - factorized_top_k/top_5_categorical_accuracy: 0.2073 - factorized_top_k/top_10_categorical_accuracy: 0.2789 - factorized_top_k/top_50_categorical_accuracy: 0.4435 - factorized_top_k/top_100_categorical_accuracy: 0.5186 - loss: 37147.3935 - regularization_loss: 0.0000e+00 - total_loss: 37147.3935 - val_factorized_top_k/top_1_categorical_accuracy: 0.0258 - val_factorized_top_k/top_5_categorical_accuracy: 0.0945 - val_factorized_top_k/top_10_categorical_accuracy: 0.1298 - val_factorized_top_k/top_50_categorical_accuracy: 0.2275 - val_factorized_top_k/top_100_categorical_accuracy: 0.2794 - val_loss: 11624.1084 - val_regularization_loss: 0.0000e+00 - val_total_loss: 11624.1084\n",
      "Epoch 15/36\n",
      "187/187 [==============================] - 323s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.0169 - factorized_top_k/top_5_categorical_accuracy: 0.2072 - factorized_top_k/top_10_categorical_accuracy: 0.2794 - factorized_top_k/top_50_categorical_accuracy: 0.4445 - factorized_top_k/top_100_categorical_accuracy: 0.5194 - loss: 36959.7297 - regularization_loss: 0.0000e+00 - total_loss: 36959.7297 - val_factorized_top_k/top_1_categorical_accuracy: 0.0246 - val_factorized_top_k/top_5_categorical_accuracy: 0.0936 - val_factorized_top_k/top_10_categorical_accuracy: 0.1286 - val_factorized_top_k/top_50_categorical_accuracy: 0.2259 - val_factorized_top_k/top_100_categorical_accuracy: 0.2780 - val_loss: 11660.2842 - val_regularization_loss: 0.0000e+00 - val_total_loss: 11660.2842\n",
      "Epoch 16/36\n",
      "187/187 [==============================] - 321s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.0174 - factorized_top_k/top_5_categorical_accuracy: 0.2071 - factorized_top_k/top_10_categorical_accuracy: 0.2799 - factorized_top_k/top_50_categorical_accuracy: 0.4452 - factorized_top_k/top_100_categorical_accuracy: 0.5202 - loss: 36792.8623 - regularization_loss: 0.0000e+00 - total_loss: 36792.8623 - val_factorized_top_k/top_1_categorical_accuracy: 0.0239 - val_factorized_top_k/top_5_categorical_accuracy: 0.0928 - val_factorized_top_k/top_10_categorical_accuracy: 0.1275 - val_factorized_top_k/top_50_categorical_accuracy: 0.2247 - val_factorized_top_k/top_100_categorical_accuracy: 0.2767 - val_loss: 11694.6445 - val_regularization_loss: 0.0000e+00 - val_total_loss: 11694.6445\n",
      "Epoch 17/36\n",
      "187/187 [==============================] - 323s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.0179 - factorized_top_k/top_5_categorical_accuracy: 0.2068 - factorized_top_k/top_10_categorical_accuracy: 0.2800 - factorized_top_k/top_50_categorical_accuracy: 0.4458 - factorized_top_k/top_100_categorical_accuracy: 0.5208 - loss: 36643.3408 - regularization_loss: 0.0000e+00 - total_loss: 36643.3408 - val_factorized_top_k/top_1_categorical_accuracy: 0.0241 - val_factorized_top_k/top_5_categorical_accuracy: 0.0915 - val_factorized_top_k/top_10_categorical_accuracy: 0.1266 - val_factorized_top_k/top_50_categorical_accuracy: 0.2235 - val_factorized_top_k/top_100_categorical_accuracy: 0.2756 - val_loss: 11727.3174 - val_regularization_loss: 0.0000e+00 - val_total_loss: 11727.3174\n",
      "Epoch 18/36\n",
      "187/187 [==============================] - 323s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.0183 - factorized_top_k/top_5_categorical_accuracy: 0.2066 - factorized_top_k/top_10_categorical_accuracy: 0.2801 - factorized_top_k/top_50_categorical_accuracy: 0.4462 - factorized_top_k/top_100_categorical_accuracy: 0.5215 - loss: 36508.4421 - regularization_loss: 0.0000e+00 - total_loss: 36508.4421 - val_factorized_top_k/top_1_categorical_accuracy: 0.0233 - val_factorized_top_k/top_5_categorical_accuracy: 0.0906 - val_factorized_top_k/top_10_categorical_accuracy: 0.1258 - val_factorized_top_k/top_50_categorical_accuracy: 0.2225 - val_factorized_top_k/top_100_categorical_accuracy: 0.2745 - val_loss: 11758.4248 - val_regularization_loss: 0.0000e+00 - val_total_loss: 11758.4248\n",
      "Epoch 19/36\n",
      "187/187 [==============================] - 325s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.0186 - factorized_top_k/top_5_categorical_accuracy: 0.2065 - factorized_top_k/top_10_categorical_accuracy: 0.2802 - factorized_top_k/top_50_categorical_accuracy: 0.4466 - factorized_top_k/top_100_categorical_accuracy: 0.5221 - loss: 36385.9979 - regularization_loss: 0.0000e+00 - total_loss: 36385.9979 - val_factorized_top_k/top_1_categorical_accuracy: 0.0232 - val_factorized_top_k/top_5_categorical_accuracy: 0.0900 - val_factorized_top_k/top_10_categorical_accuracy: 0.1248 - val_factorized_top_k/top_50_categorical_accuracy: 0.2215 - val_factorized_top_k/top_100_categorical_accuracy: 0.2736 - val_loss: 11788.0752 - val_regularization_loss: 0.0000e+00 - val_total_loss: 11788.0752\n",
      "Epoch 20/36\n",
      "187/187 [==============================] - 321s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.0190 - factorized_top_k/top_5_categorical_accuracy: 0.2063 - factorized_top_k/top_10_categorical_accuracy: 0.2801 - factorized_top_k/top_50_categorical_accuracy: 0.4469 - factorized_top_k/top_100_categorical_accuracy: 0.5225 - loss: 36274.2633 - regularization_loss: 0.0000e+00 - total_loss: 36274.2633 - val_factorized_top_k/top_1_categorical_accuracy: 0.0228 - val_factorized_top_k/top_5_categorical_accuracy: 0.0891 - val_factorized_top_k/top_10_categorical_accuracy: 0.1240 - val_factorized_top_k/top_50_categorical_accuracy: 0.2207 - val_factorized_top_k/top_100_categorical_accuracy: 0.2727 - val_loss: 11816.3711 - val_regularization_loss: 0.0000e+00 - val_total_loss: 11816.3711\n",
      "Epoch 21/36\n",
      "187/187 [==============================] - 323s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.0192 - factorized_top_k/top_5_categorical_accuracy: 0.2060 - factorized_top_k/top_10_categorical_accuracy: 0.2800 - factorized_top_k/top_50_categorical_accuracy: 0.4472 - factorized_top_k/top_100_categorical_accuracy: 0.5229 - loss: 36171.8216 - regularization_loss: 0.0000e+00 - total_loss: 36171.8216 - val_factorized_top_k/top_1_categorical_accuracy: 0.0223 - val_factorized_top_k/top_5_categorical_accuracy: 0.0883 - val_factorized_top_k/top_10_categorical_accuracy: 0.1232 - val_factorized_top_k/top_50_categorical_accuracy: 0.2197 - val_factorized_top_k/top_100_categorical_accuracy: 0.2719 - val_loss: 11843.4141 - val_regularization_loss: 0.0000e+00 - val_total_loss: 11843.4141\n",
      "Epoch 22/36\n",
      "187/187 [==============================] - 323s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.0194 - factorized_top_k/top_5_categorical_accuracy: 0.2057 - factorized_top_k/top_10_categorical_accuracy: 0.2797 - factorized_top_k/top_50_categorical_accuracy: 0.4475 - factorized_top_k/top_100_categorical_accuracy: 0.5232 - loss: 36077.5064 - regularization_loss: 0.0000e+00 - total_loss: 36077.5064 - val_factorized_top_k/top_1_categorical_accuracy: 0.0223 - val_factorized_top_k/top_5_categorical_accuracy: 0.0881 - val_factorized_top_k/top_10_categorical_accuracy: 0.1224 - val_factorized_top_k/top_50_categorical_accuracy: 0.2191 - val_factorized_top_k/top_100_categorical_accuracy: 0.2710 - val_loss: 11869.2998 - val_regularization_loss: 0.0000e+00 - val_total_loss: 11869.2998\n",
      "Epoch 23/36\n",
      "187/187 [==============================] - 322s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.0196 - factorized_top_k/top_5_categorical_accuracy: 0.2053 - factorized_top_k/top_10_categorical_accuracy: 0.2795 - factorized_top_k/top_50_categorical_accuracy: 0.4477 - factorized_top_k/top_100_categorical_accuracy: 0.5235 - loss: 35990.3375 - regularization_loss: 0.0000e+00 - total_loss: 35990.3375 - val_factorized_top_k/top_1_categorical_accuracy: 0.0220 - val_factorized_top_k/top_5_categorical_accuracy: 0.0874 - val_factorized_top_k/top_10_categorical_accuracy: 0.1217 - val_factorized_top_k/top_50_categorical_accuracy: 0.2182 - val_factorized_top_k/top_100_categorical_accuracy: 0.2704 - val_loss: 11894.1172 - val_regularization_loss: 0.0000e+00 - val_total_loss: 11894.1172\n",
      "Epoch 24/36\n",
      "187/187 [==============================] - 323s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.0197 - factorized_top_k/top_5_categorical_accuracy: 0.2050 - factorized_top_k/top_10_categorical_accuracy: 0.2793 - factorized_top_k/top_50_categorical_accuracy: 0.4478 - factorized_top_k/top_100_categorical_accuracy: 0.5236 - loss: 35909.4737 - regularization_loss: 0.0000e+00 - total_loss: 35909.4737 - val_factorized_top_k/top_1_categorical_accuracy: 0.0214 - val_factorized_top_k/top_5_categorical_accuracy: 0.0870 - val_factorized_top_k/top_10_categorical_accuracy: 0.1210 - val_factorized_top_k/top_50_categorical_accuracy: 0.2178 - val_factorized_top_k/top_100_categorical_accuracy: 0.2699 - val_loss: 11917.9434 - val_regularization_loss: 0.0000e+00 - val_total_loss: 11917.9434\n",
      "Epoch 25/36\n",
      "187/187 [==============================] - 321s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.0199 - factorized_top_k/top_5_categorical_accuracy: 0.2047 - factorized_top_k/top_10_categorical_accuracy: 0.2790 - factorized_top_k/top_50_categorical_accuracy: 0.4480 - factorized_top_k/top_100_categorical_accuracy: 0.5238 - loss: 35834.1923 - regularization_loss: 0.0000e+00 - total_loss: 35834.1923 - val_factorized_top_k/top_1_categorical_accuracy: 0.0212 - val_factorized_top_k/top_5_categorical_accuracy: 0.0862 - val_factorized_top_k/top_10_categorical_accuracy: 0.1205 - val_factorized_top_k/top_50_categorical_accuracy: 0.2171 - val_factorized_top_k/top_100_categorical_accuracy: 0.2694 - val_loss: 11940.8486 - val_regularization_loss: 0.0000e+00 - val_total_loss: 11940.8486\n",
      "Epoch 26/36\n",
      "156/187 [========================>.....] - ETA: 38s - factorized_top_k/top_1_categorical_accuracy: 0.0200 - factorized_top_k/top_5_categorical_accuracy: 0.2048 - factorized_top_k/top_10_categorical_accuracy: 0.2794 - factorized_top_k/top_50_categorical_accuracy: 0.4494 - factorized_top_k/top_100_categorical_accuracy: 0.5253 - loss: 35820.9929 - regularization_loss: 0.0000e+00 - total_loss: 35820.9929"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32me:\\Documents\\Python\\retail-recommenders\\training\\retrieval_user_item_model.ipynb Cell 9\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/e%3A/Documents/Python/retail-recommenders/training/retrieval_user_item_model.ipynb#X11sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m model\u001b[39m.\u001b[39;49mfit(cached_train, epochs\u001b[39m=\u001b[39;49m\u001b[39m36\u001b[39;49m, validation_data\u001b[39m=\u001b[39;49mcached_test, callbacks\u001b[39m=\u001b[39;49m[tensorboard_callback])\n",
      "File \u001b[1;32mc:\\Users\\anand.HOME\\Anaconda3\\envs\\tf\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\anand.HOME\\Anaconda3\\envs\\tf\\lib\\site-packages\\keras\\engine\\training.py:1564\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1556\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[0;32m   1557\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   1558\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1561\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[0;32m   1562\u001b[0m ):\n\u001b[0;32m   1563\u001b[0m     callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1564\u001b[0m     tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[0;32m   1565\u001b[0m     \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[0;32m   1566\u001b[0m         context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[1;32mc:\\Users\\anand.HOME\\Anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\anand.HOME\\Anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    912\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    914\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 915\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m    917\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    918\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32mc:\\Users\\anand.HOME\\Anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    944\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[0;32m    945\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    946\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 947\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateless_fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    948\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateful_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    949\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    950\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[0;32m    951\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[1;32mc:\\Users\\anand.HOME\\Anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2496\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2493\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m   2494\u001b[0m   (graph_function,\n\u001b[0;32m   2495\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2496\u001b[0m \u001b[39mreturn\u001b[39;00m graph_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[0;32m   2497\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mgraph_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
      "File \u001b[1;32mc:\\Users\\anand.HOME\\Anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1862\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1858\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1859\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1860\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1861\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1862\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall(\n\u001b[0;32m   1863\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager))\n\u001b[0;32m   1864\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1865\u001b[0m     args,\n\u001b[0;32m   1866\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1867\u001b[0m     executing_eagerly)\n\u001b[0;32m   1868\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[1;32mc:\\Users\\anand.HOME\\Anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:499\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    497\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[0;32m    498\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 499\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[0;32m    500\u001b[0m         \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignature\u001b[39m.\u001b[39;49mname),\n\u001b[0;32m    501\u001b[0m         num_outputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_outputs,\n\u001b[0;32m    502\u001b[0m         inputs\u001b[39m=\u001b[39;49margs,\n\u001b[0;32m    503\u001b[0m         attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[0;32m    504\u001b[0m         ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[0;32m    505\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    506\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    507\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[0;32m    508\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    511\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n\u001b[0;32m    512\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32mc:\\Users\\anand.HOME\\Anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[0;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     56\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit(cached_train, epochs=36, validation_data=cached_test, callbacks=[tensorboard_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ERROR: Timed out waiting for TensorBoard to start. It may still be running as pid 140028."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir logs/fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(cached_test, return_dict=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('tf')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d7f156ea84fdc221bcc828ba074462c25de1a00a239b7857dab945319d42b0e1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
